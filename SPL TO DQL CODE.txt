SPL --->

index="main" sourcetype="access_combined" 
| rex field=_raw "\"\w+\s[^\"]+\"\s(?<status>\d{3})\s" 
| chart
    eval(round(avg(req_time),2)) as avgSVCTime
    count(eval(status=200)) as numOf200Errors,
    count(eval(status=404)) as numOf404Errors,
    count(eval(status=301)) as numOf301Errors,
    count(eval(status=206)) as numOf206Errors,
    count(eval(status=403)) as numOf403Errors,
    by clientip 
| fields - avgSVCTime

DQL --->

fetch logs
| filter matchesValue(log.source, "apache.log")
| parse content, "IPADDR:clientip LD '[' HTTPDATE ']' LD 'HTTP/' LD SPACE INT:status LD"
| summarize numOf200Errors=countIf(status==200), numOf404Errors=countIf(status==404), numOf301Errors=countIf(status==301), numOf206Errors=countIf(status==206), numOf403Errors=countIf(status==403), by:{clientip}


======================================================================================================================

SPL ---> 

index="main" sourcetype="access_combined" 
| rex field=_raw "^(?<client_ip>\d{1,3}(?:\.\d{1,3}){3})" 
| stats count by client_ip 
| sort -count 
| head 10


DQL --->

fetch logs
| filter matchesValue(log.source, "apache.log")
| parse content, "IPADDR:clientip LD '[' HTTPDATE ']' LD 'HTTP/' LD SPACE INT LD"
| summarize total_count=count(), by:{clientip}
| sort - total_count
| limit 10

=======================================================================================================================
SPL --->

index="main" sourcetype="access_combined" 
| rex field=_raw "\"\w+\s[^\"]+\"\s(?<status>\d{3})\s" 
| search status=404 
| stats count as error_404_count by clientip, referer_domain

DQL ---> 

fetch logs
| filter matchesValue(log.source, "apache.log")
| parse content, "IPADDR:clientip LD '[' HTTPDATE ']' LD 'HTTP/' LD SPACE INT:status SPACE INT LD:url SPACE"
| parse url,"LD:referer_domain'.com'"
| fieldsAdd new_referer_domain = concat("http://",referer_domain,".com")
| filterOut new_referer_domain=="http://.com"
| summarize total_count=countIf(status==404), by:{clientip,referer_domain}
| parse referer_domain, "LD '/' LD:referer_domain"
| fieldsAdd referer_domain=concat("http:/",referer_domain,".com")
| fields clientip, referer_domain, total_count

=====================================================================================================================

SPL --->

index="main" sourcetype="access_combined" 
| rex field=_raw "^(?<client_ip>\d{1,3}(?:\.\d{1,3}){3})" 
| stats count by client_ip useragent 
| sort -count 
| head 10

DQL --->

fetch logs
| filter matchesValue(log.source, "apache.log")
| parse content, "IPADDR:clientip LD '[' HTTPDATE ']' LD 'HTTP/' LD SPACE INT:status SPACE INT LD:url"
| parse url, "LD SPACE LD:useragent"
| parse useragent, "DQS:useragent"
| summarize total_count=count(), by:{clientip,useragent}
| filterOut useragent=="-"
| sort - total_count
| filter isNotNull(useragent)
| limit 10

=====================================================================================================================

SPL --->

index="main" sourcetype="access_combined" 
| rex field=_raw "\"\w+\s(?<url>[^\s]+)" 
| where url like "%.exe" OR url like "%.sh" OR url like "%.php" 
| stats count by url

DQL --->

fetch logs
| filter matchesValue(log.source, "apache.log")
| parse content, "IPADDR:clientip LD '[' HTTPDATE ']' LD:url 'HTTP/'"
| parse url, "LD SPACE LD:url"
| fieldsAdd php=contains(url,".php"), exe=contains(url,".exe"), sh=contains(url,".sh")
| filter php==true OR exe==true OR sh==true
| summarize total_count=count(), by:{url}

=====================================================================================================================

SPL --->

index="main" sourcetype="access_combined" 
| rex field=_raw "\"\w+\s(?<url>[^\s]+)\sHTTP" 
| stats count by url 
| where url ="/favicon.ico" 
| where count > 500


DQL --->

fetch logs
| filter matchesValue(log.source, "apache.log")
| parse content, "IPADDR:clientip LD '[' HTTPDATE ']' LD:url 'HTTP/'"
| parse url, "LD SPACE LD:url"
| filter contains(url, "/favicon.ico")
| summarize total_count=count(), by:{url}
| filter total_count>500

======================================================================================================================
SPL --->

index="main" sourcetype="access_combined"
|rex field=_raw "\"\w+\s(?&lt;url&gt;[^\s]+)\sHTTP/[^\"]+\"\s(?&lt;status&gt;\d{3})"
|rex field=_raw "^(?&lt;client_ip&gt;\d{1,3}(?:\.\d{1,3}){3})" 
| where status="404"
|stats count by url
|rename url as result, count as occurences 
|eval type="Top 404 URLS"

DQL --->

fetch logs
| filter matchesValue(log.source, "apache.log")
| parse content, "IPADDR:clientip LD '[' HTTPDATE ']' LD:url 'HTTP/' LD SPACE INT:status SPACE LD"
| parse url, "LD SPACE LD:url"
| filter status==404
| summarize occurences=count() ,by:{url}
| fieldsRename result=url
|fieldsAdd type="Top 404 URLS"

=====================================================================================================================

SPL --->

index=main source=Sample_tickets.csv 
| table ticket_number 
| join ticket_number type=inner 
    [ search index=main source=Sample_lookup.csv 
    | table ticket_number, time_taken]
	
DQL ---> 

fetch logs
| filter matchesValue(log.source, "sample_tickets.csv")
| sort timestamp desc
| parse content, "LD ',INC' LD:ticket_number ',' LD"
| fieldsAdd ticket_number = concat("INC",ticket_number)
| join [fetch logs
| filter matchesValue(log.source, "sample_lookup.csv")
| sort timestamp desc
| parse content, "LD:ticket_number ',' LD:time_taken"] , on:{ticket_number}, kind:{inner}